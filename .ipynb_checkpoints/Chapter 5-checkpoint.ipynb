{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01b8e49",
   "metadata": {},
   "source": [
    "# Cross-Validation and the Bootstrap Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d72acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce4b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate,\n",
    "KFold,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598f8ca",
   "metadata": {},
   "source": [
    "### Use the function train_test_split() to split the data into training train_test_split() and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7ffb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c4802",
   "metadata": {},
   "source": [
    "### Fitting a linear regression using only the observations corresponding to the training set Auto_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52f47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3967a4",
   "metadata": {},
   "source": [
    "### Use the predict() method of results evaluated on the model matrix for this model created using the validation data set. We also calculatethe validation MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c101d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.616617069669882"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b80400",
   "metadata": {},
   "source": [
    "### Estimate the validation error for higher-degree polynomial regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deaf0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "   \n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f6cf4",
   "metadata": {},
   "source": [
    "### To estimate the validation MSE using linear, quadratic and cubic fits. We use the enumerate() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac94c0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                        Auto_train,\n",
    "                        Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81021635",
   "metadata": {},
   "source": [
    "### If we choose a different training/validation split instead, then we can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e6aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a8282",
   "metadata": {},
   "source": [
    "## Using sklearn to perform cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d8640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c3c6b",
   "metadata": {},
   "source": [
    "### To use cross_validate() function to produce a dictionary with several components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39776e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443031, 19.03322397])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82ae1b",
   "metadata": {},
   "source": [
    "### Introducing the outer() method of the np.power() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159c5f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955594b",
   "metadata": {},
   "source": [
    "### We use random_state to set a random seed and initialize a vector cv_error in which we will store the CV errors corresponding to the polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d564f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848403, 19.1371939 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820c66c",
   "metadata": {},
   "source": [
    "### Use the ShuffleSplit() funtion to implement the validation set approach just as easily as K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace82f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec3ad9",
   "metadata": {},
   "source": [
    "###  Estimating the variability in the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3419faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034164, 1.4218450941091862)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821a972",
   "metadata": {},
   "source": [
    "# The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49adcf",
   "metadata": {},
   "source": [
    "### The Portfolio data set in the ISLP package to estimate the sampling variance of the parameter α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6fe5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) /\n",
    "            (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf238c3c",
   "metadata": {},
   "source": [
    "### The function alpha_func() returns an estimate for α based on applying the minimum variance formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf7d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f302f",
   "metadata": {},
   "source": [
    "### Randomly select 100 observations from range(100), with replacement. This is equivalent to constructing a new bootstrap data set and recomputing αˆ based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd847d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cfcf3f",
   "metadata": {},
   "source": [
    "### To create a simple function boot_SE() for computing the bootstrap standard error for arbitrary functions that take only a data frame as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ed5876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264604d",
   "metadata": {},
   "source": [
    "### Using our function to evaluate the accuracy of our estimate of α using B = 1,000 bootstrap replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6e7a00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277699"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da32df9",
   "metadata": {},
   "source": [
    "### Use the clone() function to make a copy of the formula that can clone() be refit to the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76910526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae155b59",
   "metadata": {},
   "source": [
    "### Use function partial() to freeze the first two model-formula arguments of boot_OLS()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "092fd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194bf5b",
   "metadata": {},
   "source": [
    "### Use hp_func() function to create bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86012680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.12226577, -0.1555926 ],\n",
       "       [37.18648613, -0.13915813],\n",
       "       [37.46989244, -0.14112749],\n",
       "       [38.56723252, -0.14830116],\n",
       "       [38.95495707, -0.15315141],\n",
       "       [39.12563927, -0.15261044],\n",
       "       [38.45763251, -0.14767251],\n",
       "       [38.43372587, -0.15019447],\n",
       "       [37.87581142, -0.1409544 ],\n",
       "       [37.95949036, -0.1451333 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "np.array([\n",
    "    hp_func(\n",
    "        Auto,\n",
    "        rng.choice(Auto.index, size=len(Auto), replace=True)\n",
    "    )\n",
    "    for _ in range(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c44ca",
   "metadata": {},
   "source": [
    "###  Use the boot_SE() function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ba64c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.731176\n",
       "horsepower    0.006092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func,\n",
    "                Auto,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ccdd0",
   "metadata": {},
   "source": [
    "### Compute the standard errors for the regression coefficients in a linear model using the summarize() function from ISLP.sm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f5c3842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a12f9",
   "metadata": {},
   "source": [
    "### Compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96e678d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.538641\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "                    quad_model,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea53838",
   "metadata": {},
   "source": [
    "### Compare the results to the standard errors computed using sm.OLS()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1232b2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
